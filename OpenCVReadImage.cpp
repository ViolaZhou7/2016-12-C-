//opencv
#include "opencv2/opencv.hpp"
#include <opencv2/imgproc.hpp>
#include <opencv2/core/core.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/video/background_segm.hpp>
//C++
#include <iostream>
#include <sstream>
#include <fstream>
#include <cstdio>
#include <vector>

using namespace cv;
using namespace std;

// global variables
// frame read from input
Mat frame;
// fore ground mask generated by MOG2 method
Mat fgMaskMOG2;
// MOG2 Background subtractor
Ptr<BackgroundSubtractor> pMOG2;
// input from keyboard
int keyboard;
// the length of reference area by assumption
float ref_length = 5.0;
// fps by assumption
int fps = 30;
// used for warp frame in perspective transformation
vector<int> coordX;
vector<int> coordY;

// used for finding contours of moving objects
Mat src; 
Mat src_gray;
int thresh = 120;  // increase thresh to reduce noise
int max_thresh = 255;	// max possible thresh
RNG rng(12345);
Mat threshold_output;
Mat canny_output;
vector<vector<Point> > contours;
vector<Vec4i> hierarchy;
vector<vector<Point> > contours_poly(contours.size());
vector<Rect> boundRect(contours.size());
vector<Point2f>center(contours.size());
vector<float>radius(contours.size());
Mat vehicle_contour;

//void processVideo(char* videoFilename);
void processImages(char* firstFrameFilename);
void warp_perspect(string frameFilename);
void get_coordinates(Mat img);
void onMouse(int event, int x, int y, int flags, void* param);
void findMOGContours(string imageToSave);
void thresh_callback(int, void*);

int main(int argc, char* argv[])
{
	/*// use 111_png/input/.. to test optical flow
	Mat frame1, frame2;
	Mat gray_frame1, gray_frame2;
	vector<Point2f> features1, features2;


	frame2 = imread("111_png/input/1.png");
	cvtColor(frame2, gray_frame2, COLOR_BGR2GRAY);
	goodFeaturesToTrack(gray_frame2, features2, 30, 0.01, 0);
	for (int i = 2; i <= 1499; i++)
	{
	vector<uchar> status;
	Mat err;
	string number = to_string (i);
	gray_frame1 = gray_frame2;
	features1 = features2;
	frame2 = imread("111_png/input/" + number + ".png");
	cvtColor(frame2, gray_frame2, COLOR_BGR2GRAY);
	goodFeaturesToTrack(gray_frame2, features2, 30, 0.01, 0);
	//TermCriteria termcrit(TermCriteria::COUNT | TermCriteria::EPS, 20, 0.03);
	calcOpticalFlowPyrLK(gray_frame1, gray_frame2, features1, features2, status, err);
	//Draw lines connecting previous position and current position
	for (int j = 0; j<features2.size(); j++) {
	if (status[j]) {
	cout << "ok " << i << "    " << j << endl;
	line(frame2, features1[j], features2[j], Scalar(0, 0, 255),2,8,0);
	}
	}




	imshow("Test", frame2);
	waitKey(100);
	}*/


	//create GUI windows
	namedWindow("Frame");
	namedWindow("FG Mask MOG 2");




	//pMOG2 = createBackgroundSubtractorMOG2(500, 16, true); //MOG2 approach, opencv 3.0.0, default parameter
	pMOG2 = createBackgroundSubtractorMOG2(); //MOG2 approach




	if (strcmp(argv[1], "-img") == 0) {
		//-----------------------input data coming from a sequence of images----------------------------
		processImages(argv[2]);
	}
	else {
		//error in reading input parameters
		cerr << "Please, check the input parameters." << endl;
		cerr << "Exiting..." << endl;
		return EXIT_FAILURE;
	}




	//destroy GUI windows
	destroyAllWindows();
	return EXIT_SUCCESS;
}




void processImages(char* firstFrameFilename)  // first frame is: 111_png/input2/999.png
{
	// read the first file
	//frame = imread(firstFrameFilename);

	// deal with frame
	int count = 0;
	float speed;
	stringstream ssf;
	string str;
	ssf << firstFrameFilename;
	ssf >> str;
	frame = imread(firstFrameFilename);
	get_coordinates(frame);
	warp_perspect(firstFrameFilename);

	//Add two reference pts on the new graph, to construct two horizontal reference lines
	get_coordinates(frame);


	// current frame file name
	string fn(firstFrameFilename);




	// read input data, ESC or 'q' for quiting
	while ((char)keyboard != 'q' && (char)keyboard != 27)
	{
		warp_perspect(fn);

		// apply bg subtraction on current frame and retrieve fgMaskMOG2
		pMOG2->apply(frame, fgMaskMOG2);
		size_t index = fn.find_last_of("/");
		if (index == string::npos) {
			index = fn.find_last_of("\\");
		}
		size_t index2 = fn.find_last_of(".");
		string prefix = fn.substr(0, index + 1);
		string suffix = fn.substr(index2);
		string frameNumberString = fn.substr(index + 1, index2 - index - 1);


		// save the fg mask to specified dir
		string imageToSave = "111_png\\fgMask\\" + frameNumberString + ".png";
		bool saved = imwrite(imageToSave, fgMaskMOG2);
		//cout << "image to save: " << imageToSave << endl;
		int frameNumber = stoi(frameNumberString);
		rectangle(frame, cv::Point(10, 2), cv::Point(100, 20),
			cv::Scalar(255, 255, 255), -1);
		putText(frame, frameNumberString.c_str(), cv::Point(15, 15),
			FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(0, 0, 0));




		// draw sample reference lines
		line(frame, Point(0.0, coordY[4]), Point(640.0, coordY[4]), Scalar(0, 255, 0), 1, 8, 0);
		line(frame, Point(0.0, coordY[5]), Point(640.0, coordY[5]), Scalar(0, 255, 0), 1, 8, 0);
		line(fgMaskMOG2, Point(0.0, coordY[4]), Point(640.0, coordY[4]), Scalar(0, 255, 0), 1, 8, 0);
		line(fgMaskMOG2, Point(0.0, coordY[5]), Point(640.0, coordY[5]), Scalar(0, 255, 0), 1, 8, 0);




		//show the current frame and the fg masks
		imshow("Frame", frame);
		imshow("FG Mask MOG 2", fgMaskMOG2);




		//for each fg Mask, find countours
		findMOGContours(imageToSave);
		
		// speed estimation CAN BE IMPROVED BY APPLYING OPTICAL FLOW OR OTHER TECHNIQUES
		// find the y-coordinate of the lowest point in the contour
		int bottom_pt = 0;
		for (int i = 0; i < contours.size(); i++)
		{
			for (int j = 0; j < contours[i].size(); j++)
			{
				if (bottom_pt < contours[i][j].y)
				{
					bottom_pt = contours[i][j].y;
				}
			}
		}
		
		// compare the lowest point with the upper reference line
		// there is moving object enters the reference area
		if (bottom_pt >= coordY[4]) 
		{
			// the lowest point of the contour still exists inside reference area
			if (bottom_pt < coordY[5])
			{
				// count # of frames with the moving object in the reference area
				count += 1;
			}
			else
			{
				if (count != 0)
				{
					speed = ref_length / (float(count) / float(fps));
					cout << "Estimated speed: " << speed << endl;
				}
				count = 0;
			}
		}

		keyboard = waitKey(30);

		// search for the next image in the sequence
		frameNumber++;
		string nextFrameNumberString = to_string(frameNumber);  // next frame number starts from 2
		string nextFrameFilename = prefix + nextFrameNumberString + suffix;

		// read the next frame
		frame = imread(nextFrameFilename);

		if (frame.empty()) {
			//error in opening the next image in the sequence
			cerr << "Unable to open image frame: " << nextFrameFilename << endl;
			exit(EXIT_FAILURE);
		}

		//update the path of the current frame
		fn.assign(nextFrameFilename);
	}
}

void warp_perspect(string frameFilename)
{
	//get_coordinates(frameFilename);
	Point2f inputQuad[4];
	// Output Quadilateral or World plane coordinates
	Point2f outputQuad[4];

	// Lambda Matrix
	Mat lambda(2, 4, CV_32FC1);
	//Input and Output Image;
	Mat input, output;
	//Load the image
	input = imread(frameFilename);
	// Set the lambda matrix the same type and size as input
	lambda = Mat::zeros(input.rows, input.cols, input.type());

	// The 4 points that select quadilateral on the input
	// These four pts are the sides of the rect box used as input 
	inputQuad[0] = Point2f(coordX[0], coordY[0]);
	inputQuad[1] = Point2f(coordX[1], coordY[1]);
	inputQuad[2] = Point2f(coordX[2], coordY[2]);
	inputQuad[3] = Point2f(coordX[3], coordY[3]);
	// The 4 points where the mapping is to be done
	outputQuad[0] = Point2f(0, 0);
	outputQuad[1] = Point2f(0, 480);
	outputQuad[2] = Point2f(640, 0);
	outputQuad[3] = Point2f(640, 480);

	// Get the Perspective Transform Matrix i.e. lambda 
	lambda = getPerspectiveTransform(inputQuad, outputQuad);
	// Apply the Perspective Transform just found to the src image
	warpPerspective(input, output, lambda, output.size());

	//Display input and output
	//imshow("Input", input);
	//imshow("Output", output);
	frame = output;
	//waitKey(0);
}

// capture mouse action and convert to coordinates
void onMouse(int event, int x, int y, int flags, void* param) {
	//IplImage* img = (IplImage*)param;
	if (event == EVENT_LBUTTONDOWN) {
		printf("%d,%d\n", x, y);
		coordX.push_back(x);
		coordY.push_back(y);
	}
}

// get coordinates of 4 corner points
void get_coordinates(Mat img)
{
	namedWindow("Output Window");
	cv::setMouseCallback("Output Window", onMouse, &img);
	imshow("Output Window", img);
	waitKey(0);
	destroyWindow("Output Window");
}

void findMOGContours(string imageToSave)
{
	src = imread(imageToSave);
	cvtColor(src, src_gray, COLOR_BGR2GRAY);
	blur(src_gray, src_gray, Size(3, 3));
	//namedWindow("FG Mask");
	//imshow("FG Mask", src);

	//find countours
	createTrackbar(" Threshold:", "Source", &thresh, max_thresh, thresh_callback);
	thresh_callback(0, 0);
	//waitKey(0);
}

void thresh_callback(int, void*)
{
	// Detect edges using Threshold
	//threshold(src_gray, threshold_output, thresh, 255, THRESH_BINARY);
	// Detect edges using canny, src_gray is gray scaled source frame
	Canny(src_gray, canny_output, thresh, thresh * 2, 3);
	// Find contours
	findContours(canny_output, contours, hierarchy, RETR_TREE, CHAIN_APPROX_SIMPLE, Point(0, 0));

	//findContours(threshold_output, contours, hierarchy, RETR_TREE, CHAIN_APPROX_SIMPLE, Point(0, 0));
	/*// output contours to .csv file
	ofstream ct;
	ct.open("contours.csv");
	for (int i = 0; i < contours.size(); i++)
	ct << contours[i] << endl;
	*/

	// Approximate contours to polygons + get bounding rects and circles
	/*for (int i = 0; i < contours.size(); i++)
	{
	approxPolyDP(Mat(contours[i]), contours_poly[i], 3, true);
	boundRect[i] = boundingRect(Mat(contours_poly[i]));
	minEnclosingCircle((Mat)contours_poly[i], center[i], radius[i]);
	}*/

	// Draw polygonal contour + bonding rects + circles
	/*Mat drawing = Mat::zeros(threshold_output.size(), CV_8UC3);
	for (int i = 0; i< contours.size(); i++)
	{
	if (radius[i] >= 20)  // in order to discard noise
	{
	Scalar color = Scalar(rng.uniform(0, 255), rng.uniform(0, 255), rng.uniform(0, 255));
	drawContours(drawing, contours_poly, i, color, 1, 8, vector<Vec4i>(), 0, Point());
	rectangle(drawing, boundRect[i].tl(), boundRect[i].br(), color, 1, 8, 0);
	circle(drawing, center[i], (int)radius[i], color, 1, 8, 0);
	}
	}*/

	//Draw contours
	Mat drawing = Mat::zeros(canny_output.size(), CV_8UC3);
	for (int i = 0; i< contours.size(); i++)
	{
		Scalar color = Scalar(rng.uniform(0, 255), rng.uniform(0, 255), rng.uniform(0, 255));
		drawContours(drawing, contours, i, color, 1, 8, hierarchy, 0, Point());
	}

	// draw two reference lines in output image "drawing"
	line(drawing, Point(0.0, coordY[4]), Point(640.0, coordY[4]), Scalar(0, 255, 0), 1, 8, 0);
	line(drawing, Point(0.0, coordY[5]), Point(640.0, coordY[5]), Scalar(0, 255, 0), 1, 8, 0);

	// Show in a window
	namedWindow("Contours");
	imshow("Contours", drawing);
}
